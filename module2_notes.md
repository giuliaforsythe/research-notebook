consider the ethical, moral, and legal dimensions of big data research

#Theorizing Research Practices 

We Forgot to Theorize Twenty Years Ago

http://hdl.handle.net/2142/50034

*scholarly evidences of search practices
*does it strengthen confirmation bias
*uses the word "hermeneutic" about a dozen times

*open-ended strategy, we can map the print record by allowing an algorithm to organize the language of a collection -clusters of terms that tend to occur in the same contexts. (known  as  ‘‘topic  modeling’’)  reveals  discursive patterns that the researcher didn’t necessarily go looking for.

*"Researchers can never afford to treat algorithms as black boxes that generate mysterious authority."
*be aware of assumptions


c.f. ‘‘Topic modeling’’ is a name for a large family of algorithms, but the algorithm most commonly used by humanists is latent Dirichlet allocation (LDA). For an accessible  humanistic  introduction,
see  Ted  Underwood,  ‘‘Topic  Modeling Made Just Simple Enough,’’
The Stone and the Shell, April 7, 2012, http://ted
underwood.com/2012/04/07/topic-modeling-made-just-simple-enough/.  For a more technical account, see David Blei, ‘‘Probabilistic Topic Models,’’Communications of the ACM 55 (2012): 77–84

